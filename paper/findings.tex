\section{Findings and Future Work}
\label{sec:relwork}

%Related Work (``somewhat related'' work goes here; directly related work
%goes into the Introduction)~\cite{dsd13}.
\subsection{Analysis of Results}

NEEDS to be more specific.\\
\begin{table}[!h]
    \centering
    \begin{tabular}{| m{4cm} | m{0.75cm}| m{0.75cm} | m{0.75cm} |} \hline
        Vulnerability & $\#$ of Apps & Avg. $\#$ & Avg. $\#$ min. 1\\ \hline
        Unused Permissions & 90 & 6.01 & 6.48\\ \hline
        Dangerous Permission Combinations & 62 & 1.21 & 1.89\\ \hline            
        Unrequested Permissions & 0 & 0 & 0\\ \hline
        Overridden Trust Manager & 60 & 3.06 & 4.50\\ \hline
        Overridden Error Handler & 51  & 1.34 & 2.55\\ \hline
        Allow All Hostname Verifier & 20 & 0.25 & 1.26\\ \hline
        Mixed-Use SSL& 90 & 49.51 & 52.77 \\ \hline
        Improper Handling of addJavascriptInterface & 80 & 3.67 & 4.75 \\ \hline
    \end{tabular}
    \caption{Shows the number of apps that each vulnerability was found in, the average number of instances found of each vulnerability overall, and the average number of instances in apps where at least one instance was found.}
    \label{tab:my_label}
\end{table}

Through our experiments, we see that the majority of applications
(out of the 97 we analyzed) contain vulnerabilities within their
code. This indicates improper security practices are at play for 
most of the apps we analyzed.

When considering our sample size as representative of all 
applications on the Google Play store, the rate at which 
vulnerabilites are found is quite alarming. Many applications
available on the market, according to our study, have a significant 
chance of containing a vulnerability that allows for a third-party 
malicious attack.

For evaluating our results, we chose to invesitgate how each experiment potentially would produce false positives. Analyzing each and the results they produced, 
we discuss our approximate percentages of how many of the apps may also produce false positives. 

Exp 1
False positives within the permissions experiment are not exactly an issue. Unused permissions would have a 100\% true positive rate (granted the Androguard library works as intended). 
This is due to the fact that all unsued permissions are a potentially vulnerable exploit that can always be avoided with developers checking and seeing what permissions are actually needed within the app. 
Dangerous permission 

Exp 2
%False positives can arise for this experiment in situations where a safely implemented override occurs (i.e. a developer creates a new, safe trust manager or error handler). 
%It is also possible when a developer fully trusts a remote server, and feels they do not have to undergo the verification of a certificate.
For this experiment 

Exp 3
False positives for the AllowAllHostnameVerifier experiment may arise if an instance of the AllowAllHostnameVerifier 
class is found within an app, but is located in dead code. Manually verifying if an instance of a vulnerability is located 
in dead code, however, is not in the scope of this project. 
We assume that anytime this class is found to be implemented, the hostname verification process is not being carried out properly. 



%False positives also may include situations where this verifier is located in dead code or commented out.

Exp 4
%False positives can arise in this experiment in situations where HTTP content being loaded by an HTTPS page is known and trusted by a developer.IFF on this 
%Another chance for a false positive arises when the script finds "http://" in dead code. 

Exp 5
%False positives can occur in this experiment in situations where the addJavascriptInterface method is implemented (without any @JavascriptInterface annotations in the class), but the developer trusts the source of the content being used within the webview.



\subsection{Future Work}
If we were to continue this research in the future, we would 
want to explore some of the following areas. 

First and foremost, we would like to have more thorough experiments. 
Our experiments currently utilize the Androguard library in 
order to parse the apk files and find simple string matches. 
One example is from experiment two, where we search for 
overridden built-in methods. This experiment is fairly simplistic
and could be expanded upon into something where the method 
internals are also automatically checked to view if they are 
forgoing original intended use, making the user vulnerable.

Additionally, we would like to expand our set of Android 
applications to test on. If we were able to test on a larger 
set of apps, this would allow us to draw more accurate 
conclusions and notice more common trends in regards to 
vulnerabilities. This would allow us to develop a more 
comprehensive tool and experiments. 

Finally, instead of just utilizing static analysis, breaking 
into the domain of dynamic analysis could prove to be beneficial 
in seeing how these vulnerabilities can be exploited in real time. 
This would give us a chance to see how our predictions of 
vulnerabilities holds in a test environment of the application 
running. The results could prove valuable to enforce our 
findings and potentially find more vulnerabilities that were 
not found in static analysis. 
